{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35100971-5073-44c2-978c-152347a95fc1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  productAsin country        date  isVerified  ratingScore  \\\n",
      "0  B09G9BL5CP   India  11-08-2024        True            4   \n",
      "1  B09G9BL5CP   India  16-08-2024        True            5   \n",
      "2  B09G9BL5CP   India  14-05-2024        True            4   \n",
      "3  B09G9BL5CP   India  24-06-2024        True            5   \n",
      "4  B09G9BL5CP   India  18-05-2024        True            5   \n",
      "\n",
      "               reviewTitle                                  reviewDescription  \\\n",
      "0               No charger  Every thing is good about iPhones, there's not...   \n",
      "1          iPhone 13 256GB  It look so fabulous, I am android user switche...   \n",
      "2  Flip camera option nill  I tried to flip camera while recording but no ...   \n",
      "3                  Product                                       100% genuine   \n",
      "4             Good product         Happy to get the iPhone 13 in Amazon offer   \n",
      "\n",
      "                                           reviewUrl  \\\n",
      "0  https://www.amazon.in/gp/customer-reviews/R345...   \n",
      "1  https://www.amazon.in/gp/customer-reviews/R2HJ...   \n",
      "2  https://www.amazon.in/gp/customer-reviews/R3Y7...   \n",
      "3  https://www.amazon.in/gp/customer-reviews/R1P9...   \n",
      "4  https://www.amazon.in/gp/customer-reviews/R1XI...   \n",
      "\n",
      "                            reviewedIn                       variant  \\\n",
      "0  Reviewed in India on 11 August 2024  Colour: MidnightSize: 256 GB   \n",
      "1  Reviewed in India on 16 August 2024  Colour: MidnightSize: 256 GB   \n",
      "2     Reviewed in India on 14 May 2024  Colour: MidnightSize: 256 GB   \n",
      "3    Reviewed in India on 24 June 2024  Colour: MidnightSize: 256 GB   \n",
      "4     Reviewed in India on 18 May 2024  Colour: MidnightSize: 256 GB   \n",
      "\n",
      "  variantAsin  \n",
      "0  B09G9BQS98  \n",
      "1  B09G9BQS98  \n",
      "2  B09G9BQS98  \n",
      "3  B09G9BQS98  \n",
      "4  B09G9BQS98  \n",
      "\n",
      "\n",
      "\n",
      " productAsin           0\n",
      "country               0\n",
      "date                  0\n",
      "isVerified            0\n",
      "ratingScore           0\n",
      "reviewTitle           0\n",
      "reviewDescription    86\n",
      "reviewUrl            16\n",
      "reviewedIn            0\n",
      "variant               0\n",
      "variantAsin           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "\n",
      " ratingScore\n",
      "5    1604\n",
      "1     587\n",
      "4     461\n",
      "3     239\n",
      "2     171\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      " Cleaned data:  0       Every thing good iPhones nothing compared spee...\n",
      "1       It look fabulous I android user switched apple...\n",
      "2       I tried flip camera recording facility added Y...\n",
      "3                                             100 genuine\n",
      "4                        Happy get iPhone 13 Amazon offer\n",
      "                              ...                        \n",
      "3057    Useless phon never buy heat n useless camera p...\n",
      "3058    iam happy product charger provided apple extra...\n",
      "3059                                           Good phone\n",
      "3060    While charging mobile getting hot even using m...\n",
      "3061    Battery power bad need chat daily basis withou...\n",
      "Name: cleaned_review, Length: 3062, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Data Loading\n",
    "data = pd.read_csv('iphone.csv')\n",
    "print(data.head())\n",
    "print(\"\\n\\n\\n\", data.isnull().sum())\n",
    "print(\"\\n\\n\\n\", data['ratingScore'].value_counts())\n",
    "\n",
    "#Text Cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return ' '\n",
    "    \n",
    "data['cleaned_review'] = data['reviewDescription'].apply(preprocess_text)\n",
    "print(\"\\n\\n Cleaned data: \",data['cleaned_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72647dd3-7c22-4e1d-98cf-2cb7b4d58680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sentiment Labels:\n",
      " 0    2\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "4    2\n",
      "Name: label, dtype: int64\n",
      "Epoch 1/5\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6611 - loss: 0.8403 - val_accuracy: 0.5710 - val_loss: 0.9473\n",
      "Epoch 2/5\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7659 - loss: 0.6160 - val_accuracy: 0.7178 - val_loss: 0.7577\n",
      "Epoch 3/5\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8684 - loss: 0.3731 - val_accuracy: 0.7618 - val_loss: 0.6885\n",
      "Epoch 4/5\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9058 - loss: 0.2491 - val_accuracy: 0.7830 - val_loss: 0.6932\n",
      "Epoch 5/5\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9370 - loss: 0.1833 - val_accuracy: 0.7847 - val_loss: 0.7606\n",
      "Compiled and ready to predict!!!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "#Sentiment Classification\n",
    "\n",
    "def assign_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 2 #Positive\n",
    "    elif rating ==3:\n",
    "        return 1 #Neutral\n",
    "    else:\n",
    "        return 0 #Negative\n",
    "\n",
    "data['label'] = data['ratingScore'].apply(assign_sentiment)\n",
    "print(\"Data Sentiment Labels:\\n\", data['label'].head())\n",
    "\n",
    "#Tokenization\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(data['cleaned_review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['cleaned_review'])\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "y = data['label']\n",
    "\n",
    "#Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=128),\n",
    "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "print(\"Compiled and ready to predict!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bf5f963-c45c-4899-8f02-c159fc31872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X)\n",
    "data['predicted_sentiment'] = predictions.argmax(axis=1)\n",
    "data.to_csv('sentiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1dcfe-d99a-4aa7-906c-685d5ccf4072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
